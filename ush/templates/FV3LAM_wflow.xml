{#

This is a Jinja-enabled Rocoto XML template. It is filled in using the
fill_template.py script, and is done automatically by the
generate_workflow.sh step of preparing a regional workflow configured
experiment.

See README.xml_templating.md for information on using the Templating mechanisms.
-#}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workflow [

<!--
Parameters needed by the job scheduler.
-->
<!ENTITY ACCOUNT         "{{ account }}">
<!ENTITY SERVICE_ACCOUNT "{{ service_account }}">
<!ENTITY SCHED           "{{ sched }}">
<!ENTITY QUEUE_DEFAULT   "{{ queue_default }}">
<!ENTITY QUEUE_HPSS      "{{ queue_hpss }}">
<!ENTITY QUEUE_FCST      "{{ queue_fcst }}">
<!ENTITY QUEUE_ANALYSIS  "{{ queue_analysis }}">
<!ENTITY QUEUE_GRAPHICS  "{{ queue_graphics }}">
<!ENTITY RRFS_RESERVE  {% if reservation %}"--reservation={{ reservation }}"{% else %}""{% endif %}>

<!--
Workflow task names.
-->
<!ENTITY MAKE_GRID_TN      "{{ make_grid_tn }}">
<!ENTITY MAKE_OROG_TN      "{{ make_orog_tn }}">
<!ENTITY MAKE_SFC_CLIMO_TN "{{ make_sfc_climo_tn }}">
<!ENTITY GET_EXTRN_ICS_TN  "{{ get_extrn_ics_tn }}">
<!ENTITY GET_EXTRN_LBCS_TN "{{ get_extrn_lbcs_tn }}">
<!ENTITY GET_EXTRN_LBCS_LONG_TN "{{ get_extrn_lbcs_long_tn }}">
<!ENTITY MAKE_ICS_TN       "{{ make_ics_tn }}">
<!ENTITY MAKE_LBCS_TN      "{{ make_lbcs_tn }}">
<!ENTITY RUN_FCST_TN       "{{ run_fcst_tn }}">
<!ENTITY RUN_POST_TN       "{{ run_post_tn }}">
<!ENTITY ANAL_GSI_TN       "{{ anal_gsi }}">
<!ENTITY PREP_COLDSTART_TN "{{ prep_coldstart }}">
<!ENTITY PREP_WARMSTART_TN "{{ prep_warmstart }}">

<!ENTITY PROCESS_RADAR_REF_TN "{{ process_radarref }}">
<!ENTITY PROCESS_LIGHTNING_TN "{{ process_lightning }}">
<!ENTITY PROCESS_BUFR_TN      "{{ process_bufr }}">
<!ENTITY RADAR_REFL2TTEN_TN   "{{ radar_refl2tten }}">
<!ENTITY CLDANL_NONVAR_TN     "{{ cldanl_nonvar }}">

<!ENTITY RUN_PREPSTART_TN  "run_prepstart">
<!ENTITY RUN_ANAL_TN       "run_anal_gsi">
<!ENTITY RUN_BUFR_TN       "run_bufr">
<!ENTITY RUN_NCL_TN        "run_ncl">
<!ENTITY RUN_NCL_ZIP_TN    "run_ncl_zip">
<!ENTITY CLEAN_TN          "run_clean">
<!ENTITY ARCHIVE_TN        "run_archive">

<!ENTITY TAG               "{{ tag }}">

<!--
Flags that specify whether to run the preprocessing tasks.
-->
<!ENTITY RUN_TASK_MAKE_GRID      "{{ run_task_make_grid | upper }}">
<!ENTITY RUN_TASK_MAKE_OROG      "{{ run_task_make_orog | upper }}">
<!ENTITY RUN_TASK_MAKE_SFC_CLIMO "{{ run_task_make_sfc_climo | upper }}">

<!--
Number of physical cores per node for the current machine.  This is used
below in the <nodesize> tag, but that tag is not clearly documented.  This
parameter may be unnecessary since each task now has its own variable that
specifies the number of processes per node being used (the PPN_... entities).
-->
<!ENTITY NCORES_PER_NODE "{{ ncores_per_node }}">

<!--
Directories and files.
-->
<!ENTITY JOBSDIR                  "{{ jobsdir }}">
<!ENTITY LOGDIR                   "{{ logdir }}">
<!ENTITY CYCLE_BASEDIR            "{{ cycle_basedir }}">
{%- if is_rtma %}
<!ENTITY FG_ROOT                  "{{ fg_rootdir }}">
{%- else %}
<!ENTITY FG_ROOT                  "{{ cycle_basedir }}">
{%- endif %}
<!ENTITY GLOBAL_VAR_DEFNS_FP      "{{ global_var_defns_fp }}">
<!ENTITY LOAD_MODULES_RUN_TASK_FP "{{ load_modules_run_task_fp }}">

<!--
Reservation types.  Reservations specify the queue/partition and account
to use for a given task.  The "DEFAULT" reservation type is used for all 
tasks other than GET_EXTRN_ICS_TN, GET_EXTRN_LBCS_TN, and RUN_FCST_TN; 
the "HPSS" type is used for the GET_EXTRN_ICS_TN and GET_EXTRN_LBCS_TN 
tasks; and the "FCST" type is used for the RUN_FCST_TN task.
-->
{%- if partition_default is not none %}
<!ENTITY RSRV_DEFAULT "<account>&ACCOUNT;</account><queue>&QUEUE_DEFAULT;</queue><partition>{{ partition_default }}</partition><native>&RRFS_RESERVE;</native>">
{%- else %}
<!ENTITY RSRV_DEFAULT "<account>&ACCOUNT;</account><queue>&QUEUE_DEFAULT;</queue>">
{%- endif %}
{%- if partition_hpss is not none %}
<!ENTITY RSRV_HPSS    "<account>&SERVICE_ACCOUNT;</account><queue>&QUEUE_HPSS;</queue><partition>{{ partition_hpss }}</partition>">
{%- else %}
<!ENTITY RSRV_HPSS    "<account>&SERVICE_ACCOUNT;</account><queue>&QUEUE_HPSS;</queue>">
{%- endif %}
{%- if partition_fcst is not none %}
<!ENTITY RSRV_FCST    "<account>&ACCOUNT;</account><queue>&QUEUE_FCST;</queue><partition>{{ partition_fcst }}</partition>">
{%- else %}
<!ENTITY RSRV_FCST    "<account>&ACCOUNT;</account><queue>&QUEUE_FCST;</queue>">
{%- endif %}
{%- if partition_analysis is not none %}
<!ENTITY RSRV_ANALYSIS    "<account>&ACCOUNT;</account><queue>&QUEUE_ANALYSIS;</queue><partition>{{ partition_analysis }}</partition>">
{%- else %}
<!ENTITY RSRV_ANALYSIS    "<account>&ACCOUNT;</account><queue>&QUEUE_ANALYSIS;</queue>">
{%- endif %}
<!ENTITY RSRV_GRAPHICS   "<account>&SERVICE_ACCOUNT;</account><queue>&QUEUE_GRAPHICS;</queue><partition>{{ partition_graphics }}</partition>">

<!ENTITY DEADLINE_PRE      "16:00:00">
<!ENTITY DEADLINE_ANAL     "16:00:00">
<!ENTITY DEADLINE_FCST     "23:30:00">
<!ENTITY DEADLINE_POST     "24:00:00">
<!ENTITY DEADLINE_GRAPHICS "24:00:00">

<!ENTITY START_TIME_ANALYSIS     "02:37:00">
<!ENTITY START_TIME_CONVENTIONAL "00:37:00">
<!ENTITY START_TIME_NSSLMOSIAC   "00:45:00">
<!ENTITY START_TIME_LIGHTNINGNC  "00:45:00">

<!ENTITY WALL_LIMIT_PRE '<deadline><cyclestr offset="&DEADLINE_PRE;">@Y@m@d@H@M</cyclestr></deadline>'>
<!ENTITY WALL_LIMIT_ANAL '<deadline><cyclestr offset="&DEADLINE_ANAL;">@Y@m@d@H@M</cyclestr></deadline>'>
<!ENTITY WALL_LIMIT_FCST '<deadline><cyclestr offset="&DEADLINE_FCST;">@Y@m@d@H@M</cyclestr></deadline>'>
<!ENTITY WALL_LIMIT_POST '<deadline><cyclestr offset="&DEADLINE_POST;">@Y@m@d@H@M</cyclestr></deadline>'>
<!ENTITY WALL_LIMIT_BUFR '<deadline><cyclestr offset="&DEADLINE_POST;">@Y@m@d@H@M</cyclestr></deadline>'>
<!ENTITY WALL_LIMIT_GRAPHICS '<deadline><cyclestr offset="&DEADLINE_GRAPHICS;">@Y@m@d@H@M</cyclestr></deadline>'>



]>

<workflow realtime="T" scheduler="&SCHED;" cyclethrottle="24" cyclelifespan="01:00:00:00">
{# Double quotes are required inside the strftime! Expect an error from reading the template if using single quotes. #}
  <cycledef group="at_start">{{ at_start_cycledef }} </cycledef>

  <cycledef group="initial"> {{ initial_cycledef }} </cycledef>
  <cycledef group="boundary"> {{ boundary_cycledef }} </cycledef>
  <cycledef group="boundary_long"> {{ boundary_long_cycledef }} </cycledef>

  <cycledef group="prep_coldstart"> {{ prep_coldstart_cycledef }} </cycledef>
  <cycledef group="prep_warmstart"> {{ prep_warmstart_cycledef }} </cycledef>

  <cycledef group="analysis"> {{ analysis_cycledef }} </cycledef>
  <cycledef group="forecast"> {{ forecast_cycledef }} </cycledef>
  <cycledef group="archive">  {{ archive_cycledef }} </cycledef> 

  <log>
    <cyclestr>&LOGDIR;/FV3LAM_wflow.log</cyclestr>
  </log>

<!-- 
The following command works to call the J-job for a given task (in this
case the MAKE_GRID_TN task) if in the script LOAD_MODULES_RUN_TASK_FP we 
do NOT call exec to run the J-job.  The command first sources the script
LOAD_MODULES_RUN_TASK_FP and then runs the J-job, so it is simpler than
calling exec and thus preferred if NCO accepts it.  Note that the portion
of the command that sources LOAD_MODULES_RUN_TASK_FP also passes an 
argument to it (the argument being the name of the task).  This works in
bash but it probably won't work in sh.

If this method is acceptable to NCO, then for clarity maybe we can
source LOAD_MODULES_RUN_TASK_FP within the J-job instead of here since
we are already sourcing other files in the J-job anyway.
-->
<!--
    <command>{ . &LOAD_MODULES_RUN_TASK_FP; "&MAKE_GRID_TN;";
               &JOBSDIR;/JREGIONAL_MAKE_GRID;
             }</command>
-->
<!--
The following command works if we call exec in LOAD_MODULES_RUN_TASK_FP
to run the J-job.  This passes the J-job script as the second argument
to LOAD_MODULES_RUN_TASK_FP (the first argument is the task name).  The
J-job then uses exec to run the J-job (while also terminating the LOAD_-
MODULES_RUN_TASK_FP script.
-->

{% if run_task_make_grid %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_GRID_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_grid }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_GRID_TN;" "&JOBSDIR;/JREGIONAL_MAKE_GRID"</command>
  {% if machine in ["WCOSS_DELL_P3", "WCOSS_CRAY"]  %}
    <nodes>{{ nnodes_make_grid }}:ppn=1</nodes>
  {% else %}
    <nodes>{{ nnodes_make_grid }}:ppn={{ ppn_make_grid }}</nodes>
  {% endif %}
    <walltime>{{ wtime_make_grid }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&MAKE_GRID_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_GRID_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

  </task>
{% endif %}

{% if run_task_make_orog %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_OROG_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_orog }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_OROG_TN;" "&JOBSDIR;/JREGIONAL_MAKE_OROG"</command>
  {% if machine in ["WCOSS_DELL_P3", "WCOSS_CRAY"]  %}
    <nodes>{{ nnodes_make_orog }}:ppn=1</nodes>
  {% else %}
    <nodes>{{ nnodes_make_orog }}:ppn={{ ppn_make_orog }}</nodes>
  {% endif %}
    <walltime>{{ wtime_make_orog }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&MAKE_OROG_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_OROG_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

    <dependency>
      <or>
<!--        <taskdep task="make_grid"/> -->
        <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
        <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
      </or>
    </dependency>

  </task>
{% endif %}

{% if run_task_make_sfc_climo %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_SFC_CLIMO_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_sfc_climo }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_SFC_CLIMO_TN;" "&JOBSDIR;/JREGIONAL_MAKE_SFC_CLIMO"</command>
    <nodes>{{ nnodes_make_sfc_climo }}:ppn={{ ppn_make_sfc_climo }}</nodes>
    <walltime>{{ wtime_make_sfc_climo }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&MAKE_SFC_CLIMO_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_SFC_CLIMO_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

    <dependency>
      <and>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>
{% endif %}

{% if not is_rtma %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&GET_EXTRN_ICS_TN;" cycledefs="initial" maxtries="{{ maxtries_get_extrn_ics }}">

    &WALL_LIMIT_PRE;
    &RSRV_HPSS;
  {% if machine in ["WCOSS_CRAY"] %}
    <shared/>
  {% endif %}
    <command>&LOAD_MODULES_RUN_TASK_FP; "&GET_EXTRN_ICS_TN;" "&JOBSDIR;/JREGIONAL_GET_EXTRN_MDL_FILES"</command>
  {% if machine in ["WCOSS_DELL_P3"] %}
    <memory>2048M</memory><native>-R affinity[core]</native>
  {% endif %}
    <nodes>{{ nnodes_get_extrn_ics }}:ppn={{ ppn_get_extrn_ics }}</nodes>
    <walltime>{{ wtime_get_extrn_ics }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&GET_EXTRN_ICS_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&GET_EXTRN_ICS_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>EXTRN_MDL_NAME</name><value>{{ extrn_mdl_name_ics }}</value></envar>
    <envar><name>ICS_OR_LBCS</name><value>ICS</value></envar>

    <dependency>
      <datadep age="00:00:05:00"><cyclestr offset="-{{ extrn_mdl_ics_offset_hrs }}:00:00">{{ extrn_mdl_sysbasedir_ics }}/@y@j@H000{{ "%03d" % extrn_mdl_ics_offset_hrs }}</cyclestr></datadep>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&GET_EXTRN_LBCS_TN;" cycledefs="boundary" maxtries="{{ maxtries_get_extrn_lbcs }}">

    &WALL_LIMIT_PRE;
    &RSRV_HPSS;
  {% if machine in ["WCOSS_CRAY"] %}
    <shared/>
  {% endif %}
    <command>&LOAD_MODULES_RUN_TASK_FP; "&GET_EXTRN_LBCS_TN;" "&JOBSDIR;/JREGIONAL_GET_EXTRN_MDL_FILES"</command>
  {% if machine in ["WCOSS_DELL_P3"] %}
    <memory>2048M</memory><native>-R affinity[core]</native>
  {% endif %}
    <nodes>{{ nnodes_get_extrn_lbcs }}:ppn={{ ppn_get_extrn_lbcs }}</nodes>
    <walltime>{{ wtime_get_extrn_lbcs }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&GET_EXTRN_LBCS_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&GET_EXTRN_LBCS_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>EXTRN_MDL_NAME</name><value>{{ extrn_mdl_name_lbcs }}</value></envar>
    <envar><name>ICS_OR_LBCS</name><value>LBCS</value></envar>
    <envar><name>BOUNDARY_LEN</name><value>{{ boundary_len_hrs }}</value></envar>

    <dependency>
       <and>
         {%- for h in range(extrn_mdl_lbcs_offset_hrs, boundary_len_hrs+extrn_mdl_lbcs_offset_hrs+1, bc_update_interval) %}
         <datadep age="00:00:05:00"> <cyclestr offset="-{{ extrn_mdl_lbcs_offset_hrs }}:00:00">{{ extrn_mdl_sysbasedir_lbcs }}/@y@j@H000{{ "%03d" % h }}</cyclestr></datadep>
         {%- endfor %}
       </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&GET_EXTRN_LBCS_LONG_TN;" cycledefs="boundary_long" maxtries="{{ maxtries_get_extrn_lbcs }}">

    &WALL_LIMIT_PRE;
    &RSRV_HPSS;
  {% if machine in ["WCOSS_CRAY"] %}
    <shared/>
  {% endif %}
    <command>&LOAD_MODULES_RUN_TASK_FP; "&GET_EXTRN_LBCS_TN;" "&JOBSDIR;/JREGIONAL_GET_EXTRN_MDL_FILES"</command>
  {% if machine in ["WCOSS_DELL_P3"] %}
    <memory>2048M</memory><native>-R affinity[core]</native>
  {% endif %}
    <nodes>{{ nnodes_get_extrn_lbcs }}:ppn={{ ppn_get_extrn_lbcs }}</nodes>
    <walltime>{{ wtime_get_extrn_lbcs }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&GET_EXTRN_LBCS_LONG_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&GET_EXTRN_LBCS_LONG_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>EXTRN_MDL_NAME</name><value>{{ extrn_mdl_name_lbcs }}</value></envar>
    <envar><name>ICS_OR_LBCS</name><value>LBCS</value></envar>
    <envar><name>BOUNDARY_LEN</name><value>{{ boundary_long_len_hrs }}</value></envar>

    <dependency>
       <and>
         {%- for h in range(extrn_mdl_lbcs_offset_hrs, boundary_long_len_hrs+extrn_mdl_lbcs_offset_hrs+1, bc_update_interval) %}
         <datadep age="00:00:05:00"> <cyclestr offset="-{{ extrn_mdl_lbcs_offset_hrs }}:00:00">{{ extrn_mdl_sysbasedir_lbcs }}/@y@j@H000{{ "%03d" % h }}</cyclestr></datadep>
         {%- endfor %}
       </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
{%- if do_ensemble %}
  <metatask name="run_ensemble">

    <var name="{{ ensmem_indx_name }}">
{%- for m in range(1, num_ens_members+1) -%}
  {%- set fmtstr=" %0"~ndigits_ensmem_names~"d" -%}
  {{- fmtstr%m -}}
{%- endfor %} </var>
{%- endif %}

  <task name="&MAKE_ICS_TN;{{ uscore_ensmem_name }}" cycledefs="initial" maxtries="{{ maxtries_make_ics }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_PRE;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_ICS_TN;" "&JOBSDIR;/JREGIONAL_MAKE_ICS"</command>
    <nodes>{{ nnodes_make_ics }}:ppn={{ ppn_make_ics }}</nodes>
    <walltime>{{ wtime_make_ics }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&MAKE_ICS_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_ICS_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>

    <dependency>
      <and>
        <taskdep task="&GET_EXTRN_ICS_TN;"/>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_SFC_CLIMO_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_SFC_CLIMO_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_SFC_CLIMO;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_LBCS_TN;{{ uscore_ensmem_name }}" cycledefs="boundary,boundary_long" maxtries="{{ maxtries_make_lbcs }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_PRE;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_LBCS_TN;" "&JOBSDIR;/JREGIONAL_MAKE_LBCS"</command>
    <nodes>{{ nnodes_make_lbcs }}:ppn={{ ppn_make_lbcs }}</nodes>
    <walltime>{{ wtime_make_lbcs }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&MAKE_LBCS_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_LBCS_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>

    <dependency>
      <and>
        <or>
          <taskdep task="&GET_EXTRN_LBCS_TN;"/>
          <taskdep task="&GET_EXTRN_LBCS_LONG_TN;"/>
        </or>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_SFC_CLIMO_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_SFC_CLIMO_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_SFC_CLIMO;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>

<!--
************************************************************************
************************************************************************
-->
  <task name="&PREP_COLDSTART_TN;" cycledefs="prep_coldstart" maxtries="{{ maxtries_run_prepstart }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_PRE;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_PREPSTART_TN;" "&JOBSDIR;/JREGIONAL_RUN_PREPSTART"</command>

    <nodes>{{ nnodes_run_prepstart }}:ppn={{ ppn_run_prepstart }}</nodes>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <walltime>{{ wtime_run_prepstart }}</walltime>
    <jobname>&TAG;_&PREP_COLDSTART_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&PREP_COLDSTART_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>FG_ROOT</name><value><cyclestr>&CYCLE_BASEDIR;</cyclestr></value></envar>
    <envar><name>BKTYPE</name><value><cyclestr>1</cyclestr></value></envar>

    <dependency>
      <and>
        <timedep><cyclestr offset="&START_TIME_CONVENTIONAL;">@Y@m@d@H@M00</cyclestr></timedep>
        <taskdep task="&MAKE_ICS_TN;"/>
        {%- if not do_dacycle %}
        <taskdep task="&MAKE_LBCS_TN;"/>
        {%- endif %}
      </and>
    </dependency>

  </task>

{%- endif %}
<!--
************************************************************************
************************************************************************
-->

  <task name="&PREP_WARMSTART_TN;" cycledefs="prep_warmstart" maxtries="{{ maxtries_run_prepstart }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_PRE;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_PREPSTART_TN;" "&JOBSDIR;/JREGIONAL_RUN_PREPSTART"</command>
    <nodes>{{ nnodes_run_prepstart }}:ppn={{ ppn_run_prepstart }}</nodes>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <walltime>{{ wtime_run_prepstart }}</walltime>
    <jobname>&TAG;_&PREP_WARMSTART_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&PREP_WARMSTART_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>FG_ROOT</name><value><cyclestr>&FG_ROOT;</cyclestr></value></envar>
    <envar><name>BKTYPE</name><value><cyclestr>0</cyclestr></value></envar>

    <dependency>
      <or>
        <and>
          <timedep><cyclestr offset="&START_TIME_CONVENTIONAL;">@Y@m@d@H@M00</cyclestr></timedep>
          <datadep age="00:00:05:00"><cyclestr offset="-{{ da_cycle_interval_hrs }}:00:00">&FG_ROOT;/@Y@m@d@H/fcst_fv3lam/dynf00{{ da_cycle_interval_hrs }}.nc</cyclestr></datadep>
        </and>
        <and>
          <timedep><cyclestr offset="&START_TIME_ANALYSIS;">@Y@m@d@H@M00</cyclestr></timedep>
          <or>
            {%- for h in range(da_cycle_interval_hrs+da_cycle_interval_hrs, 6+1, da_cycle_interval_hrs) %}
            <datadep age="00:00:05:00"><cyclestr offset="-{{ h }}:00:00">&FG_ROOT;/@Y@m@d@H/fcst_fv3lam/dynf{{ "%03d" % h}}.nc</cyclestr></datadep>
            {%- endfor %}
          </or>
        </and>
      </or>
    </dependency>

  </task>

{%- if do_nonvar_cldanal or do_refl2tten %}
<!--
************************************************************************
************************************************************************
--> 
  <task name="&PROCESS_RADAR_REF_TN;" cycledefs="analysis"  maxtries="{{ maxtries_process_radarref }}">
    
    &RSRV_DEFAULT;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_PROCESS_RADARREF"</command>
      
    <nodes>{{ nnodes_proc_radar }}:ppn={{ ppn_proc_radar }};</nodes>
    <walltime>{{ wtime_proc_radar }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&PROCESS_RADAR_REF_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&PROCESS_RADAR_REF_TN;_@Y@m@d@H.log</cyclestr></join>
        
    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
        
    <dependency>
      <and>
        <timedep><cyclestr offset="&START_TIME_NSSLMOSIAC;">@Y@m@d@H@M00</cyclestr></timedep>
      </and>
    </dependency>

  </task>

<!--
************************************************************************
************************************************************************
-->
  <task name="&PROCESS_LIGHTNING_TN;" cycledefs="analysis"  maxtries="{{ maxtries_process_lightning }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_PROCESS_LIGHTNING"</command>

    <nodes>{{ nnodes_proc_lightning }}:ppn={{ ppn_proc_lightning }};</nodes>
    <walltime>{{ wtime_proc_lightning }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&PROCESS_LIGHTNING_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&PROCESS_LIGHTNING_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>

    <dependency>
      <and>
        <timedep><cyclestr offset="&START_TIME_LIGHTNINGNC;">@Y@m@d@H@M00</cyclestr></timedep>
      </and>
    </dependency>

  </task>

<!--
************************************************************************
************************************************************************
-->
  <task name="&PROCESS_BUFR_TN;" cycledefs="analysis"  maxtries="{{ maxtries_process_bufr }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_PROCESS_BUFR"</command>

    <nodes>{{ nnodes_proc_bufr }}:ppn={{ ppn_proc_bufr }};</nodes>
    <walltime>{{ wtime_proc_bufr }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&PROCESS_BUFR_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&PROCESS_BUFR_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>

    <dependency>
      <and>
        <timedep><cyclestr offset="&START_TIME_CONVENTIONAL;">@Y@m@d@H@M00</cyclestr></timedep>
      </and>
    </dependency>

  </task>

{%- endif %}
<!--
************************************************************************
************************************************************************
-->

{%- if do_dacycle %}

  <task name="&ANAL_GSI_TN;" cycledefs="analysis" maxtries="{{ maxtries_anal_gsi }}">

    &RSRV_ANALYSIS;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_RUN_ANAL"</command>
    {% if machine in ["JET", "HERA"] -%}
    <cores>{{ ncores_run_anal }}</cores>
    <native>{{ native_run_anal }} &RRFS_RESERVE;</native>
    {% else -%}
    <nodes>{{ nnodes_run_anal }}:ppn={{ ppn_run_anal }}</nodes>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    {% endif -%}
    <walltime>{{ wtime_run_anal }}</walltime>
    <jobname>&TAG;_&ANAL_GSI_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&ANAL_GSI_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_ROOT</name><value><cyclestr>&CYCLE_BASEDIR;</cyclestr></value></envar>

    <dependency>
       <and>
         <timedep><cyclestr offset="&START_TIME_CONVENTIONAL;">@Y@m@d@H@M00</cyclestr></timedep>
         <or>
           <taskdep task="&PREP_COLDSTART_TN;"/>
           <taskdep task="&PREP_WARMSTART_TN;"/>
         </or>
       </and>
    </dependency>

  </task>
{% endif -%}

{%- if do_refl2tten %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&RADAR_REFL2TTEN_TN;" cycledefs="analysis"  maxtries="{{ maxtries_radar_ref2tten }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_REFL2TTEN"</command>
    <nodes>{{ nnodes_run_ref2tten }}:ppn={{ ppn_run_ref2tten }}</nodes>
    <walltime>{{ wtime_run_ref2tten }}</walltime>
    <memory>{{ memo_run_ref2tten }}</memory>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&RADAR_REFL2TTEN_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&RADAR_REFL2TTEN_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>

    <dependency>
      <and>
        <or>
          <taskdep task="&PROCESS_RADAR_REF_TN;"/>
          <taskdep task="&PROCESS_LIGHTNING_TN;"/>
        </or>
        <taskdep task="&ANAL_GSI_TN;"/>
      </and>
    </dependency>

  </task>

{%- endif %}

{%- if do_nonvar_cldanal %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&CLDANL_NONVAR_TN;" cycledefs="analysis"  maxtries="{{ maxtries_cldanl_nonvar }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_ANAL;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_ANAL_TN;" "&JOBSDIR;/JREGIONAL_NONVARCLD"</command>
    <nodes>{{ nnodes_run_nonvarcldanl }}:ppn={{ ppn_run_nonvarcldanl }}</nodes>
    <walltime>{{ wtime_run_nonvarcldanl }}</walltime>
    <memory>{{ memo_run_nonvarcldanl }}</memory>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&CLDANL_NONVAR_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&CLDANL_NONVAR_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>

    <dependency>
      <and>
        <taskdep task="&PROCESS_BUFR_TN;"/>
        <taskdep task="&ANAL_GSI_TN;"/>
      </and>
    </dependency>

  </task>

{%- endif %}

<!--
************************************************************************
************************************************************************
-->
  <task name="&RUN_FCST_TN;{{ uscore_ensmem_name }}" cycledefs="forecast" maxtries="{{ maxtries_run_fcst }}">

    &RSRV_FCST;
    &WALL_LIMIT_FCST;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_FCST_TN;" "&JOBSDIR;/JREGIONAL_RUN_FCST"</command>
  {% if machine in ["JET", "HERA"]  %}
    <cores>{{ ncores_run_fcst }}</cores>
    <native>{{ native_run_fcst }} &RRFS_RESERVE;</native>
  {% else %}
    <nodes>{{ nnodes_run_fcst }}:ppn={{ ppn_run_fcst }}</nodes>
    <nodesize>&NCORES_PER_NODE;</nodesize>
  {% endif %}
    <walltime>{{ wtime_run_fcst }}</walltime>
    <jobname>&TAG;_&RUN_FCST_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&RUN_FCST_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
    <envar><name>ENSMEM_INDX</name><value><cyclestr>#{{ ensmem_indx_name }}#</cyclestr></value></envar>
  
    <dependency>
      {%- if do_dacycle and do_nonvar_cldanal%}
      <taskdep task="&CLDANL_NONVAR_TN;"/>
      {%- elif do_dacycle %}
      <taskdep task="&ANAL_GSI_TN;"/>
      {%- else %}
      <or>
        <taskdep task="&PREP_COLDSTART_TN;{{ uscore_ensmem_name }}"/>
        <taskdep task="&PREP_WARMSTART_TN;{{ uscore_ensmem_name }}"/>
      </or>
      {%- endif %}
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <metatask name="&RUN_POST_TN;{{ uscore_ensmem_name }}">

    <var name="fhr"> {% for h in range(0, fcst_len_hrs+1) %}{{ " %03d" % h  }}{% endfor %} </var>

    <task name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr#" cycledefs="forecast" maxtries="{{ maxtries_run_post }}">

      &RSRV_DEFAULT;
      &WALL_LIMIT_POST;
      <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_POST_TN;" "&JOBSDIR;/JREGIONAL_RUN_POST"</command>
      <nodes>{{ nnodes_run_post }}:ppn={{ ppn_run_post }}</nodes>
      <walltime>{{ wtime_run_post }}</walltime>
      <nodesize>&NCORES_PER_NODE;</nodesize>
      <jobname>&TAG;_&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr#</jobname>
      <join><cyclestr>&LOGDIR;/&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr#_@Y@m@d@H.log</cyclestr></join>

      <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
      <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
      <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
      <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
      <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
      <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
      <envar><name>fhr</name><value>#fhr#</value></envar>

      <dependency>
        <and>
          <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H/fcst_fv3lam{{ slash_ensmem_subdir }}/dynf#fhr#.nc</cyclestr></datadep>
          <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H/fcst_fv3lam{{ slash_ensmem_subdir }}/phyf#fhr#.nc</cyclestr></datadep>
        </and>
      </dependency>

    </task>

  </metatask>

{% if do_ensemble %}
  </metatask>
{% endif %}

<!--
************************************************************************
************************************************************************
-->

  <task name="python_skewt" cycledefs="forecast" maxtries="{{ maxtries_run_post }}">

    &RSRV_GRAPHICS;
    &WALL_LIMIT_GRAPHICS;

    <walltime>{{ wtime_run_fcst }}</walltime>
    <nodes>1:ppn=24</nodes>
    <native>--exclusive</native>
    <jobname><cyclestr>&TAG;_python_@H_skewt</cyclestr></jobname>
    <join><cyclestr>&LOGDIR;/python_skewt.log</cyclestr></join>

    <command>&LOAD_MODULES_RUN_TASK_FP; "run_graphics" "&JOBSDIR;/JREGIONAL_RUN_PYTHON_GRAPHICS"</command>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
    <envar><name>GRAPHICS_TYPE</name><value>skewts</value></envar>

    <dependency>
      <taskdep task="&RUN_POST_TN;_f000"/>
    </dependency>
  </task>

<!--
************************************************************************
************************************************************************
-->
  <metatask name="&RUN_NCL_TN;">

    <var name="fhr"> {% for h in range(0, fcst_len_hrs+1) %}{{ " %03d" % h  }}{% endfor %} </var>

    <task name="&RUN_NCL_TN;_#fhr#" cycledefs="forecast" maxtries="{{ maxtries_run_post }}">

      &RSRV_GRAPHICS;
      &WALL_LIMIT_GRAPHICS;

      <command>&JOBSDIR;/../scripts/exregional_run_ncl.ksh</command>
      <walltime>00:30:00</walltime>
      <memory>24G</memory>
      <cores>16</cores>
      <jobname>&TAG;_&RUN_NCL_TN;_#fhr#</jobname>
      <join><cyclestr>&LOGDIR;/&RUN_NCL_TN;_#fhr#_@Y@m@d@H.log</cyclestr></join>

      <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
      <envar><name>START_TIME</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
      <envar><name>FCST_TIME</name><value>#fhr#</value></envar>

      <dependency>
          <taskdep task="&RUN_POST_TN;_f#fhr#"/>
      </dependency>

    </task>

   </metatask>

<!--
************************************************************************
************************************************************************
-->
   <metatask mode="serial" name="&RUN_NCL_ZIP_TN;">

    <var name="fhr"> {% for h in range(0, fcst_len_hrs+1) %}{{ " %03d" % h  }}{% endfor %} </var>

    <task name="&RUN_NCL_ZIP_TN;_#fhr#" cycledefs="forecast" maxtries="{{ maxtries_run_post }}">

      &RSRV_GRAPHICS;
      &WALL_LIMIT_GRAPHICS;

      <command>&JOBSDIR;/../scripts/exregional_run_ncl_zip.ksh</command>
      <cores>1</cores>
      <walltime>00:15:00</walltime>
      <memory>2G</memory>
      <jobname>&TAG;_&RUN_NCL_ZIP_TN;_#fhr#</jobname>
      <join><cyclestr>&LOGDIR;/&RUN_NCL_ZIP_TN;_#fhr#_@Y@m@d@H.log</cyclestr></join>

      <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
      <envar><name>START_TIME</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
      <envar><name>FCST_TIME</name><value>#fhr#</value></envar>

      <dependency>
        <or>
          <taskdep state="Dead" task="&RUN_POST_TN;_#fhr#"/>
          <taskdep state="Dead" task="&RUN_NCL_TN;_#fhr#"/>
          <taskdep task="&RUN_NCL_TN;_#fhr#"/>
        </or>
      </dependency>

    </task>

   </metatask>

{%- if do_bufr_sounding %}
<!--
     ************************************************************************
************************************************************************
-->
  <task name="&RUN_BUFR_TN;" cycledefs="analysis,forecast"  maxtries="{{ maxtries_bufr_sounding }}">

    &RSRV_DEFAULT;
    &WALL_LIMIT_BUFR;

    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_BUFR_TN;" "&JOBSDIR;/JREGIONAL_BUFR_SOUNDING"</command>
    <nodes>{{ nnodes_run_bufrsounding }}:ppn={{ ppn_run_bufrsounding }}</nodes>
    <walltime>{{ wtime_run_bufrsounding }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&TAG;_&RUN_BUFR_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&RUN_BUFR_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYC</name><value><cyclestr>@H</cyclestr></value></envar>

    <dependency>
      <and>
        <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H/fcst_fv3lam/dynf#fhr#.nc</cyclestr></datadep>
        <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H/fcst_fv3lam/phyf#fhr#.nc</cyclestr></datadep>
      </and>
    </dependency>

  </task>

{%- endif %}

<!--
************************************************************************
************************************************************************
-->
  <task name="&CLEAN_TN;" cycledefs="forecast" maxtries="{{ maxtries_run_post }}">

    &RSRV_DEFAULT;

    <command>&JOBSDIR;/../scripts/exregional_clean.ksh</command>
    <cores>1</cores>
    <walltime>00:15:00</walltime>
    <jobname>&TAG;_&CLEAN_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&CLEAN_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>LOGDIR</name><value>&LOGDIR;</value></envar>

  </task>

<!--
************************************************************************
************************************************************************
-->
  <task name="&ARCHIVE_TN;" cycledefs="archive" maxtries="{{ maxtries_run_post }}">

    &RSRV_HPSS;

    <command>&JOBSDIR;/../scripts/exregional_archive.ksh</command>
    <cores>1</cores>
    <walltime>04:00:00</walltime>
    <memory>24G</memory>
    <jobname>&TAG;_&ARCHIVE_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&ARCHIVE_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

  </task>


</workflow>
